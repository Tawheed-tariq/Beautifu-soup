{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exception Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The web is messy. Data is poorly formatted, websites go down, and closing tags go\n",
    "missing. One of the most frustrating experiences in web scraping is to go to sleep\n",
    "with a scraper running, dreaming of all the data you’ll have in your database the next\n",
    "day—only to find that the scraper hit an error on some unexpected data format and\n",
    "stopped execution shortly after you stopped looking at the screen. \n",
    "\n",
    "```html = urlopen('http://www.pythonscraping.com/pages/page1.html')```\n",
    "Two main things can go wrong in this line\n",
    "1. The page is not found on the server (or there was an error in retrieving it). `HTTPError`\n",
    "2. The server is not found `URLError`\n",
    "\n",
    "You can handle this exception in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "except URLError as e:\n",
    "    print(\"server could not be found\")\n",
    "else:\n",
    "    print(\"it worked\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every time you access a tag in a BeautifulSoup object, it’s smart to add a check to make sure the tag actually exists. If you attempt to access a tag that does not exist BeautifulSoup will return a None object.\n",
    "The problem is, attempting to access a tag on a None object itself will result in an AttributeError being thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "bs = BeautifulSoup(html.read(), 'html.parser')\n",
    "print(bs.find('nonExistentTag'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    title = bs.find('body').find('h1')\n",
    "except AttributeError as e:\n",
    "    print('tag not found')\n",
    "except HTTPError as e:\n",
    "    print(e)\n",
    "else:\n",
    "    print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When writing scrapers, it’s important to think about the overall pattern of your code\n",
    "in order to handle exceptions and make it readable at the same time. You’ll also likely\n",
    "want to heavily reuse code. Having generic functions such as getSiteHTML and\n",
    "getTitle (complete with thorough exception handling) makes it easy to quickly—\n",
    "and reliably—scrape the web."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
